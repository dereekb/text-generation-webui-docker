version: "3"

x-base-service: &base_service
    environment:
      - EXTRA_LAUNCH_ARGS="--listen --verbose" # Custom launch args (e.g., --model MODEL_NAME)
    ports:
      - 7860:7860  # Default web port
  #      - 5000:5000  # Default API port
  #      - 5005:5005  # Default streaming port
  #      - 5001:5001  # Default OpenAI API extension port
    volumes:
      - ./config/loras:/app/loras
      - ./config/models:/app/models
      - ./config/presets:/app/presets
      - ./config/prompts:/app/prompts
      - ./config/softprompts:/app/softprompts
      - ./config/training:/app/training
    stop_signal: SIGINT
    logging:
      driver:  json-file
      options:
        max-file: "3"   # number of files or file count
        max-size: '10m'
    deploy:
        resources:
          reservations:
            devices:
              - driver: nvidia
                device_ids: ['0']
                capabilities: [gpu]

name: text-generation-webui

services:
  default: &default
    <<: *base_service
    profiles: ["default"]
    build:
      context: .
      target: default
    image: textui-default

  triton: &triton
    <<: *base_service
    profiles: ["triton"]
    build:
      context: .
      target: triton
    image: textui-triton
    
  cuda: &cuda
    <<: *base_service
    profiles: ["cuda"]
    build:
      context: .
      target: cuda
    image: textui-cuda
    
  monkey-patch: &monkey-patch
    <<: *base_service
    profiles: ["monkey-patch"]
    build:
      context: .
      target: monkey-patch
    image: textui-monkey-patch
    
  llama-cublas: &llama-cublas
    <<: *base_service
    profiles: ["llama-cublas"]
    build:
      context: .
      target: llama-cublas
    image: textui-llama-cublas
